{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368b0aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N CPUS: 110\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from tifffile import imread\n",
    "from os import listdir\n",
    "\n",
    "from yoeo.main import get_dv2_model, get_upsampler_and_expr, get_hr_feats, get_lr_feats, convert_image, closest_crop\n",
    "from yoeo.utils import to_numpy\n",
    "\n",
    "from interactive_seg_backend import featurise_\n",
    "from interactive_seg_backend.configs import FeatureConfig, TrainingConfig, CRFParams\n",
    "from interactive_seg_backend.classifiers.base import Classifier\n",
    "from interactive_seg_backend.file_handling import load_labels, load_image\n",
    "from interactive_seg_backend.core import train, get_training_data, shuffle_sample_training_data, get_model\n",
    "from interactive_seg_backend.core import apply_\n",
    "from interactive_seg_backend.main import apply\n",
    "from interactive_seg_backend.utils import class_avg_miou\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "SEED = 10672\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf79c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "COLORS = np.array(color_list) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c1a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
     ]
    }
   ],
   "source": [
    "dv2 = get_dv2_model(True, device=DEVICE)\n",
    "\n",
    "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
    "cfg_path = \"../yoeo/models/configs/combined_no_shift.json\"\n",
    "\n",
    "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828e21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"fig_data/is_benchmark\"\n",
    "AllowedDatasets = Literal[\"Cu_ore_RLM\", \"Ni_superalloy_SEM\", \"T_cell_TEM\"]\n",
    "dataset: tuple[AllowedDatasets, ...] = (\"Cu_ore_RLM\", \"Ni_superalloy_SEM\", \"T_cell_TEM\")\n",
    "\n",
    "TRAIN_IMG_FNAMES: dict[AllowedDatasets, list[str]] = {\"Cu_ore_RLM\": [\"001\", \"028\", \"049\", \"068\"], \n",
    "                                                      \"Ni_superalloy_SEM\": [\"000\", \"001\", \"005\", \"007\"], \n",
    "                                                      \"T_cell_TEM\": [\"000\", \"027\", \"021\", \"105\"]\n",
    "                                                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_feats(img: Image.Image, K: int =32, existing_pca: object | None = None) -> np.ndarray:\n",
    "    hr_feats = get_hr_feats(img, dv2, upsampler, DEVICE, n_ch_in=expr.n_ch_in, existing_pca=existing_pca)\n",
    "    hr_feats_np = to_numpy(hr_feats)\n",
    "    hr_feats_np = hr_feats_np.transpose((1, 2, 0))[:, :, :K]\n",
    "    return hr_feats_np\n",
    "\n",
    "def train_model_over_images(dataset: AllowedDatasets, train_cfg: TrainingConfig) -> tuple[Classifier, object]:\n",
    "    features, labels = [], []\n",
    "    train_fnames = TRAIN_IMG_FNAMES[dataset]\n",
    "\n",
    "    pca = None\n",
    "    if train_cfg.add_dino_features:\n",
    "        imgs = []\n",
    "        for fname in sorted(listdir(f\"{PATH}/{dataset}/images\")):\n",
    "            img_path = f\"{PATH}/{dataset}/images/{fname}\"\n",
    "            arr = load_image(img_path)\n",
    "            img = Image.fromarray(arr).convert('RGB')\n",
    "            tr = closest_crop(img.height, img.width)\n",
    "            tensor = convert_image(img, tr, device_str=DEVICE)\n",
    "            imgs.append(tensor)\n",
    "\n",
    "        _, pca = get_lr_feats(dv2, imgs, n_imgs=150, fit3d=True)\n",
    "\n",
    "\n",
    "    for fname in train_fnames:\n",
    "        img_path = f\"{PATH}/{dataset}/images/{fname}.tif\"\n",
    "        labels_path = f\"{PATH}/{dataset}/labels/{fname}.tif\"\n",
    "\n",
    "        img_arr = load_image(img_path)\n",
    "        label_arr = load_labels(labels_path)\n",
    "\n",
    "        feats = featurise_(img_arr, train_cfg.feature_config)\n",
    "        if train_cfg.add_dino_features:\n",
    "            img = Image.fromarray(img_arr).convert('RGB')\n",
    "            deep_feats = get_deep_feats(img, 32, pca)\n",
    "            feats = np.concatenate((feats, deep_feats), axis=-1)\n",
    "\n",
    "        features.append(feats)\n",
    "        labels.append(label_arr)\n",
    "\n",
    "    print('Finished featurising')\n",
    "    fit, target = get_training_data(features, labels)\n",
    "    fit, target = shuffle_sample_training_data(\n",
    "        fit, target, train_cfg.shuffle_data, train_cfg.n_samples\n",
    "    )\n",
    "    model = get_model(\n",
    "        train_cfg.classifier, train_cfg.classifier_params, train_cfg.use_gpu\n",
    "    )\n",
    "    model = train(model, fit, target, None)\n",
    "    return model, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a767ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_over_images(dataset: AllowedDatasets, train_cfg: TrainingConfig, model: Classifier, verbose: bool=False, early_cutoff_n: int = -1, existing_pca: object | None = None) -> dict[str, np.ndarray]:\n",
    "    preds: dict[str, np.ndarray] = {}\n",
    "    img_fnames = sorted(listdir(f\"{PATH}/{dataset}/images\"))\n",
    "    N_imgs = len(img_fnames)\n",
    "\n",
    "    selected_imgs = img_fnames if early_cutoff_n <= 0 else img_fnames[:early_cutoff_n]\n",
    "\n",
    "    for i, fname in enumerate(selected_imgs):\n",
    "        if verbose and i % 10 == 0:\n",
    "            print(f\"[{i:02d}/{N_imgs}] - {fname}\")\n",
    "        img_path = f\"{PATH}/{dataset}/images/{fname}\"\n",
    "        img_arr = load_image(img_path)\n",
    "\n",
    "        feats = featurise_(img_arr, train_cfg.feature_config)\n",
    "        if train_cfg.add_dino_features:\n",
    "            img = Image.fromarray(img_arr).convert('RGB')\n",
    "            deep_feats = get_deep_feats(img, 32, existing_pca=existing_pca)\n",
    "            feats = np.concatenate((feats, deep_feats), axis=-1)\n",
    "\n",
    "        pred, _ = apply(model, feats, train_cfg, image=img_arr) #apply_(model, feats)\n",
    "        preds[fname] = pred\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7880ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preds(dataset: AllowedDatasets, preds: dict[str, np.ndarray]) -> float:\n",
    "    mious: list[float] = []\n",
    "    seg_fnames = sorted(listdir(f\"{PATH}/{dataset}/segmentations\"))\n",
    "    for i, fname in enumerate(seg_fnames):\n",
    "        seg_path = f\"{PATH}/{dataset}/segmentations/{fname}\"\n",
    "        pred = preds[fname]\n",
    "        ground_truth = load_labels(seg_path)\n",
    "        miou = class_avg_miou(pred, ground_truth)\n",
    "        mious.append(miou)\n",
    "    return np.mean(mious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da66ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_dataset: AllowedDatasets = \"Ni_superalloy_SEM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc9f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished featurising\n",
      "Finished featurising\n"
     ]
    }
   ],
   "source": [
    "feat_cfg = FeatureConfig()\n",
    "\n",
    "classical_train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=False, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\"},)\n",
    "classical_model, _ = train_model_over_images(chosen_dataset, classical_train_cfg)\n",
    "\n",
    "deep_train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=True, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\"},)\n",
    "deep_model, pca = train_model_over_images(chosen_dataset, deep_train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808497c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00/23] - 000.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/23] - 010.tif\n",
      "[20/23] - 020.tif\n",
      "[00/23] - 000.tif\n",
      "[10/23] - 010.tif\n",
      "[20/23] - 020.tif\n"
     ]
    }
   ],
   "source": [
    "classical_preds = apply_model_over_images(chosen_dataset, classical_train_cfg, classical_model, verbose=True)\n",
    "deep_preds = apply_model_over_images(chosen_dataset, deep_train_cfg, deep_model, verbose=True, existing_pca=pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbfdfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mIoU_classical: 0.5398494931057901 vs mIoU_deep: 0.7033107561470417\n"
     ]
    }
   ],
   "source": [
    "miou_classical = eval_preds(chosen_dataset, classical_preds)\n",
    "miou_deep = eval_preds(chosen_dataset, deep_preds)\n",
    "\n",
    "print(f\"mIoU_classical: {miou_classical} vs mIoU_deep: {miou_deep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "559f606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_FS = 25\n",
    "LABEL_FS = 23\n",
    "TICK_FS = 21\n",
    "PAD = 60\n",
    "\n",
    "def hide_axis_ticks(ax, frameoff: bool=True):\n",
    "    ax.tick_params(which=\"both\", bottom=False, top=False, left=False, right=False)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    if frameoff:\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "\n",
    "def add_stacked_rects(fig, subplot):\n",
    "    outer_pos = subplot.get_position(fig) \n",
    "\n",
    "    x0, y0 = outer_pos.x0, outer_pos.y0\n",
    "    width, height = outer_pos.width, outer_pos.height\n",
    "\n",
    "    # Base color\n",
    "    base_color = np.array(to_rgba('#bbbbbb'))\n",
    "\n",
    "    for n in range(3):  # 3 stacked layers\n",
    "        T = 0.005\n",
    "        offset = n * T  # tweak this for separation between layers\n",
    "        darken = 0.05 * n   # tweak this for how much darker each layer is\n",
    "        color = np.clip(base_color - darken, 0, 1)  # slightly darker with each layer\n",
    "\n",
    "        rect = Rectangle(\n",
    "            (x0 + T + offset, y0 + T + offset),  # move up and right a bit\n",
    "            width , height,\n",
    "            transform=fig.transFigure,\n",
    "            color=color,\n",
    "            zorder=-n - 1,  # stack order: bottom first\n",
    "            alpha=1,\n",
    "            linewidth=1,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        fig.patches.append(rect)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "img_paths = sorted(listdir(f\"{PATH}/{chosen_dataset}/images\"))[::5]\n",
    "\n",
    "n_samples = len(img_paths)\n",
    "fig, axs = plt.subplots(nrows=4, ncols=n_samples)\n",
    "\n",
    "fig.set_size_inches((18, 16))\n",
    "\n",
    "\n",
    "for i, img_fname in enumerate(img_paths):\n",
    "    img = imread(f\"{PATH}/{chosen_dataset}/images/{img_fname}\")\n",
    "    gt_seg = imread(f\"{PATH}/{chosen_dataset}/segmentations/{img_fname}\")\n",
    "\n",
    "    classical_pred = classical_preds[img_fname]\n",
    "    deep_pred = deep_preds[img_fname]\n",
    "\n",
    "    ax0, ax1, ax2, ax3 = axs[: ,i]\n",
    "    ax0.imshow(img, cmap='binary_r')\n",
    "    ax1.imshow(label2rgb(gt_seg, colors=COLORS[1:]))\n",
    "    ax2.imshow(label2rgb(classical_pred + 1, colors=COLORS[1:]))\n",
    "    ax3.imshow(label2rgb(deep_pred + 1, colors=COLORS[1:]))\n",
    "\n",
    "    if i == 0:\n",
    "        ax0.set_ylabel('Image', fontsize=TITLE_FS)\n",
    "        ax1.set_ylabel('Ground truth', fontsize=TITLE_FS)\n",
    "        ax2.set_ylabel('Classical', fontsize=TITLE_FS)\n",
    "        ax3.set_ylabel('+ HR ViT features', fontsize=TITLE_FS)\n",
    "    \n",
    "    ax0.set_title(img_fname, fontsize=TITLE_FS)\n",
    "\n",
    "    for ax in (ax0, ax1, ax2, ax3):\n",
    "        hide_axis_ticks(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb936a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "\n",
    "# Dummy image generator\n",
    "def generate_image(seed):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.rand(64, 64)\n",
    "\n",
    "# Organize data: 3 datasets, each with 4 examples, each with 4 versions (original + 3 derivatives)\n",
    "datasets = [[[generate_image(i + j*10 + k*100) for i in range(4)] for j in range(4)] for k in range(3)]\n",
    "titles = [\"Ni superalloy\", \"T cell\", \"Cu ore\"]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "outer_grid = gridspec.GridSpec(3, 4, wspace=0.2, hspace=0.2)  # 3 rows (datasets), 4 columns (examples per dataset)\n",
    "\n",
    "for i in range(3):  # Dataset rows\n",
    "\n",
    "    ax_train_label = plt.Subplot(fig, outer_grid[i, 0])\n",
    "    ax_train_label.set_ylabel(titles[i], fontsize=TITLE_FS, labelpad=PAD, rotation=90, va='center')\n",
    "    ax_test_label = plt.Subplot(fig, outer_grid[i, 2])\n",
    "    if i == 0:\n",
    "        ax_train_label.set_title('TRAIN', fontsize=TITLE_FS, pad=PAD)\n",
    "        ax_test_label.set_title('TEST', fontsize=TITLE_FS, pad=PAD)\n",
    "# \n",
    "\n",
    "    add_stacked_rects(fig, outer_grid[i, 0])\n",
    "    hide_axis_ticks(ax_train_label)\n",
    "    fig.add_subplot(ax_train_label)\n",
    "    hide_axis_ticks(ax_test_label)\n",
    "    fig.add_subplot(ax_test_label)\n",
    "\n",
    "    outer_pos = outer_grid[i, 0].get_position(fig)\n",
    "    # Coordinates of the 2x2 block to be used as background\n",
    "    x0, y0 = outer_pos.x0, outer_pos.y0\n",
    "    width, height = outer_pos.width, outer_pos.height\n",
    "\n",
    "    for j in range(4):  # 4 examples per dataset\n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(2, 2,\n",
    "                        subplot_spec=outer_grid[i, j], wspace=0, hspace=0)\n",
    "        for k in range(4):  # Each image (original + 3 derivatives)\n",
    "            ax = plt.Subplot(fig, inner_grid[k // 2, k % 2])\n",
    "            ax.imshow(datasets[i][j][k], cmap='gray')\n",
    "            ax.axis('off')\n",
    "            fig.add_subplot(ax)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Make space for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba821e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
