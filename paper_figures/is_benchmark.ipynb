{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368b0aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N CPUS: 110\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from tifffile import imread\n",
    "from os import listdir\n",
    "\n",
    "from yoeo.main import get_dv2_model, get_upsampler_and_expr, get_hr_feats\n",
    "from yoeo.utils import to_numpy\n",
    "\n",
    "from interactive_seg_backend import featurise_\n",
    "from interactive_seg_backend.configs import FeatureConfig, TrainingConfig\n",
    "from interactive_seg_backend.classifiers.base import Classifier\n",
    "from interactive_seg_backend.file_handling import load_labels, load_image\n",
    "from interactive_seg_backend.core import train, get_training_data, shuffle_sample_training_data, get_model\n",
    "from interactive_seg_backend.core import apply_\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "SEED = 10672\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf79c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "COLORS = np.array(color_list) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c1a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
     ]
    }
   ],
   "source": [
    "dv2 = get_dv2_model(True, device=DEVICE)\n",
    "\n",
    "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
    "cfg_path = \"../yoeo/models/configs/combined_no_shift.json\"\n",
    "\n",
    "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828e21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"fig_data/is_benchmark\"\n",
    "AllowedDatasets = Literal[\"Cu_ore_RLM\", \"Ni_superalloy_SEM\", \"T_cell_TEM\"]\n",
    "dataset: tuple[AllowedDatasets, ...] = (\"Cu_ore_RLM\", \"Ni_superalloy_SEM\", \"T_cell_TEM\")\n",
    "\n",
    "TRAIN_IMG_FNAMES: dict[AllowedDatasets, list[str]] = {\"Cu_ore_RLM\": [\"001\", \"028\", \"049\", \"068\"], \n",
    "                                                      \"Ni_superalloy_SEM\": [\"000\", \"001\", \"005\", \"007\"], \n",
    "                                                      \"T_cell_TEM\": [\"000\", \"027\", \"021\", \"105\"]\n",
    "                                                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_feats(img: Image.Image, K: int =32) -> np.ndarray:\n",
    "    hr_feats = get_hr_feats(img, dv2, upsampler, DEVICE, n_ch_in=expr.n_ch_in)\n",
    "    hr_feats_np = to_numpy(hr_feats)\n",
    "    hr_feats_np = hr_feats_np.transpose((1, 2, 0))[:, :, :K]\n",
    "    return hr_feats_np\n",
    "\n",
    "def train_model_over_images(dataset: AllowedDatasets, train_cfg: TrainingConfig) -> Classifier:\n",
    "    features, labels = [], []\n",
    "\n",
    "    train_fnames = TRAIN_IMG_FNAMES[dataset]\n",
    "    for fname in train_fnames:\n",
    "        img_path = f\"{PATH}/{dataset}/images/{fname}.tif\"\n",
    "        labels_path = f\"{PATH}/{dataset}/labels/{fname}.tif\"\n",
    "\n",
    "        img_arr = load_image(img_path)\n",
    "        label_arr = load_labels(labels_path)\n",
    "\n",
    "        feats = featurise_(img_arr, train_cfg.feature_config)\n",
    "        if train_cfg.add_dino_features:\n",
    "            img = Image.fromarray(img_arr).convert('RGB')\n",
    "            deep_feats = get_deep_feats(img, 32)\n",
    "            feats = np.concatenate((feats, deep_feats), axis=-1)\n",
    "\n",
    "        features.append(feats)\n",
    "        labels.append(label_arr)\n",
    "\n",
    "    print('Finished featurising')\n",
    "    fit, target = get_training_data(features, labels)\n",
    "    fit, target = shuffle_sample_training_data(\n",
    "        fit, target, train_cfg.shuffle_data, train_cfg.n_samples\n",
    "    )\n",
    "    model = get_model(\n",
    "        train_cfg.classifier, train_cfg.classifier_params, train_cfg.use_gpu\n",
    "    )\n",
    "    model = train(model, fit, target, None)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a767ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_over_images(dataset: AllowedDatasets, train_cfg: TrainingConfig, model: Classifier, verbose: bool=False, early_cutoff_n: int = -1) -> list[np.ndarray]:\n",
    "    preds: list[np.ndarray] = []\n",
    "    img_fnames = sorted(listdir(f\"{PATH}/{dataset}/images\"))\n",
    "    N_imgs = len(img_fnames)\n",
    "\n",
    "    for i, fname in enumerate(img_fnames[:early_cutoff_n]):\n",
    "        if verbose and i % 10 == 0:\n",
    "            print(f\"[{i:02d}/{N_imgs}] - {fname}\")\n",
    "        img_path = f\"{PATH}/{dataset}/images/{fname}\"\n",
    "        img_arr = load_image(img_path)\n",
    "\n",
    "        feats = featurise_(img_arr, train_cfg.feature_config)\n",
    "        if train_cfg.add_dino_features:\n",
    "            img = Image.fromarray(img_arr).convert('RGB')\n",
    "            deep_feats = get_deep_feats(img, 32)\n",
    "            feats = np.concatenate((feats, deep_feats), axis=-1)\n",
    "\n",
    "        pred, _ = apply_(model, feats)\n",
    "        preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880ee9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da66ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_dataset: AllowedDatasets = \"Ni_superalloy_SEM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc9f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished featurising\n"
     ]
    }
   ],
   "source": [
    "feat_cfg = FeatureConfig()\n",
    "train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=False, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\"},)\n",
    "\n",
    "model = train_model_over_images(chosen_dataset, train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "808497c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00/23] - 000.tif\n",
      "[10/23] - 010.tif\n",
      "[20/23] - 020.tif\n"
     ]
    }
   ],
   "source": [
    "preds = apply_model_over_images(chosen_dataset, train_cfg, model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfdfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
