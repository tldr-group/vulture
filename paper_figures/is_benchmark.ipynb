{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "368b0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from tifffile import imread\n",
    "from os import listdir\n",
    "\n",
    "from yoeo.main import get_dv2_model, get_upsampler_and_expr\n",
    "\n",
    "from interactive_seg_backend.configs import FeatureConfig, TrainingConfig\n",
    "from interactive_seg_backend.file_handling import load_labels\n",
    "from is_helpers import train_model_over_images, apply_model_over_images, eval_preds\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "SEED = 10672\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf79c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "COLORS = np.array(color_list) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c1a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
     ]
    }
   ],
   "source": [
    "dv2 = get_dv2_model(True, device=DEVICE)\n",
    "\n",
    "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
    "cfg_path = \"../yoeo/models/configs/combined_no_shift.json\"\n",
    "\n",
    "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828e21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"fig_data/is_benchmark\"\n",
    "AllowedDatasets = Literal[\"Ni_superalloy_SEM\", \"T_cell_TEM\", \"Cu_ore_RLM\"]\n",
    "dataset: tuple[AllowedDatasets, ...] = (\"Ni_superalloy_SEM\", \"T_cell_TEM\", \"Cu_ore_RLM\")\n",
    "\n",
    "TRAIN_IMG_FNAMES: dict[AllowedDatasets, list[str]] = {\"Cu_ore_RLM\": [\"004\", \"028\", \"049\", \"077\"], \n",
    "                                                      \"Ni_superalloy_SEM\": [\"000\", \"001\", \"005\", \"007\"], \n",
    "                                                      \"T_cell_TEM\": [\"000\", \"027\", \"021\", \"105\"]\n",
    "                                                      }\n",
    "\n",
    "all_classical_preds: dict[AllowedDatasets, dict[str, np.ndarray]] = {k: {} for k in dataset}\n",
    "all_deep_preds: dict[AllowedDatasets, dict[str, np.ndarray]] = {k: {} for k in dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3833d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished featurising\n",
      "Finished featurising\n",
      "[00/23] - 000.tif\n",
      "[10/23] - 010.tif\n",
      "[20/23] - 020.tif\n",
      "[00/23] - 000.tif\n",
      "[10/23] - 010.tif\n",
      "[20/23] - 020.tif\n",
      "Finished featurising\n",
      "Finished featurising\n",
      "[00/30] - 000.tif\n",
      "[10/30] - 044.tif\n",
      "[20/30] - 076.tif\n",
      "[00/30] - 000.tif\n",
      "[10/30] - 044.tif\n",
      "[20/30] - 076.tif\n",
      "Finished featurising\n",
      "Finished featurising\n",
      "[00/27] - 004.tif\n",
      "[10/27] - 049.tif\n",
      "[20/27] - 065.tif\n",
      "[00/27] - 004.tif\n",
      "[10/27] - 049.tif\n",
      "[20/27] - 065.tif\n"
     ]
    }
   ],
   "source": [
    "for ds_name in dataset:\n",
    "    chosen_dataset = ds_name\n",
    "    feat_cfg = FeatureConfig()\n",
    "\n",
    "    classical_train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=False, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\"},)\n",
    "    classical_model, _ = train_model_over_images(chosen_dataset, classical_train_cfg, PATH, TRAIN_IMG_FNAMES[chosen_dataset], dv2, upsampler, expr)\n",
    "\n",
    "    deep_train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=True, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\"},)\n",
    "    deep_model, pca = train_model_over_images(chosen_dataset, deep_train_cfg, PATH, TRAIN_IMG_FNAMES[chosen_dataset], dv2, upsampler, expr)\n",
    "\n",
    "    classical_preds = apply_model_over_images(chosen_dataset, classical_train_cfg, classical_model, PATH, dv2, upsampler, expr, verbose=True)\n",
    "    deep_preds = apply_model_over_images(chosen_dataset, deep_train_cfg, deep_model, PATH, dv2, upsampler, expr, verbose=True, existing_pca=pca)\n",
    "\n",
    "    all_classical_preds[ds_name] = classical_preds\n",
    "    all_deep_preds[ds_name] = deep_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79642ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Ni_superalloy_SEM ========\n",
      "mIoU_classical: 0.5398494931057901 vs mIoU_deep: 0.7031748112355668\n",
      "\n",
      "======== T_cell_TEM ========\n",
      "mIoU_classical: 0.389258450234841 vs mIoU_deep: 0.6698257898743982\n",
      "\n",
      "======== Cu_ore_RLM ========\n",
      "mIoU_classical: 0.8318250787943415 vs mIoU_deep: 0.8614422452045098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chosen_dataset in dataset:\n",
    "    classical_preds, deep_preds = all_classical_preds[chosen_dataset], all_deep_preds[chosen_dataset]\n",
    "    miou_classical = eval_preds(chosen_dataset, classical_preds, PATH)\n",
    "    miou_deep = eval_preds(chosen_dataset, deep_preds, PATH )\n",
    "    print(f\"======== {chosen_dataset} ========\")\n",
    "    print(f\"mIoU_classical: {miou_classical} vs mIoU_deep: {miou_deep}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559f606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_FS = 25\n",
    "LABEL_FS = 23\n",
    "TICK_FS = 21\n",
    "PAD = 60\n",
    "\n",
    "def hide_axis_ticks(ax, frameoff: bool=True):\n",
    "    ax.tick_params(which=\"both\", bottom=False, top=False, left=False, right=False)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    if frameoff:\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "\n",
    "def add_stacked_rects(fig, subplot):\n",
    "    outer_pos = subplot.get_position(fig) \n",
    "\n",
    "    x0, y0 = outer_pos.x0, outer_pos.y0\n",
    "    width, height = outer_pos.width, outer_pos.height\n",
    "\n",
    "    # Base color\n",
    "    base_color = np.array(to_rgba('#bbbbbb'))\n",
    "\n",
    "    for n in range(3):  # 3 stacked layers\n",
    "        T = 0.005\n",
    "        offset = n * T  # tweak this for separation between layers\n",
    "        darken = 0.05 * n   # tweak this for how much darker each layer is\n",
    "        color = np.clip(base_color - darken, 0, 1)  # slightly darker with each layer\n",
    "\n",
    "        rect = Rectangle(\n",
    "            (x0 + T + offset, y0 + T + offset),  # move up and right a bit\n",
    "            width , height,\n",
    "            transform=fig.transFigure,\n",
    "            color=color,\n",
    "            zorder=-n - 1,  # stack order: bottom first\n",
    "            alpha=1,\n",
    "            linewidth=1,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        fig.patches.append(rect)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5571b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "img_paths = sorted(listdir(f\"{PATH}/{chosen_dataset}/images\"))[::5]\n",
    "\n",
    "n_samples = len(img_paths)\n",
    "fig, axs = plt.subplots(nrows=4, ncols=n_samples)\n",
    "\n",
    "fig.set_size_inches((18, 16))\n",
    "\n",
    "\n",
    "for i, img_fname in enumerate(img_paths):\n",
    "    img = imread(f\"{PATH}/{chosen_dataset}/images/{img_fname}\")\n",
    "    gt_seg = imread(f\"{PATH}/{chosen_dataset}/segmentations/{img_fname}\")\n",
    "\n",
    "    classical_pred = classical_preds[img_fname]\n",
    "    deep_pred = deep_preds[img_fname]\n",
    "\n",
    "    ax0, ax1, ax2, ax3 = axs[: ,i]\n",
    "    ax0.imshow(img, cmap='binary_r')\n",
    "    ax1.imshow(label2rgb(gt_seg, colors=COLORS[1:]))\n",
    "    ax2.imshow(label2rgb(classical_pred + 1, colors=COLORS[1:]))\n",
    "    ax3.imshow(label2rgb(deep_pred + 1, colors=COLORS[1:]))\n",
    "\n",
    "    if i == 0:\n",
    "        ax0.set_ylabel('Image', fontsize=TITLE_FS)\n",
    "        ax1.set_ylabel('Ground truth', fontsize=TITLE_FS)\n",
    "        ax2.set_ylabel('Classical', fontsize=TITLE_FS)\n",
    "        ax3.set_ylabel('+ HR ViT features', fontsize=TITLE_FS)\n",
    "    \n",
    "    ax0.set_title(img_fname, fontsize=TITLE_FS)\n",
    "\n",
    "    for ax in (ax0, ax1, ax2, ax3):\n",
    "        hide_axis_ticks(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb936a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AllowedDatasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[43mAllowedDatasets\u001b[49m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNi_superalloy_SEM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[1;32m      2\u001b[0m titles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNi superalloys\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT-cells\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCu ore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_fourplot\u001b[39m(dataset: AllowedDatasets, filename: \u001b[38;5;28mstr\u001b[39m, parent_grid, classical_preds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray], deep_preds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],  is_train: \u001b[38;5;28mbool\u001b[39m, is_top_left_corner: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AllowedDatasets' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "datasets: list[AllowedDatasets] = [\"Ni_superalloy_SEM\"] \n",
    "titles = [\"Ni superalloys\", \"T-cells\", \"Cu ore\"]\n",
    "\n",
    "\n",
    "\n",
    "def do_fourplot(dataset: AllowedDatasets, filename: str, parent_grid, classical_preds: dict[str, np.ndarray], deep_preds: dict[str, np.ndarray],  is_train: bool, is_top_left_corner: bool = False):\n",
    "    inner_grid = gridspec.GridSpecFromSubplotSpec(2, 2,\n",
    "                subplot_spec=parent_grid, wspace=0.01, hspace=0.01)\n",
    "\n",
    "    def optional_crop(arr: np.ndarray, dataset: AllowedDatasets) -> np.ndarray:\n",
    "        if dataset == \"Cu_ore_RLM\":\n",
    "            return arr[:512, :512]\n",
    "        else:\n",
    "            return arr\n",
    "\n",
    "    for k in range(4):  # Each image (original + 3 derivatives)\n",
    "        ax = plt.Subplot(fig, inner_grid[k // 2, k % 2])\n",
    "        # ax.imshow(datasets[i][j][k], cmap='gray')\n",
    "        hide_axis_ticks(ax)\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        if is_very_top_corner and k < 2:\n",
    "            ax.set_title(subfig_titles[k], fontsize=LABEL_FS-5, pad=20)\n",
    "        elif is_very_top_corner and k >= 2:\n",
    "            ax.set_xlabel(subfig_titles[k], fontsize=LABEL_FS-5, labelpad=0)\n",
    "        \n",
    "        if k == 0:\n",
    "            img = optional_crop(imread(f\"{PATH}/{dataset}/images/{filename}\"))\n",
    "\n",
    "            if is_train:\n",
    "                labels = optional_crop(imread(f\"{PATH}/{dataset}/labels/{filename}\"))\n",
    "                labels_unsqueezed = np.expand_dims(labels[0], -1)\n",
    "\n",
    "                overlay = label2rgb(labels[0], colors=COLORS[1:], kind='overlay', bg_label=0, image_alpha=1, alpha=1)\n",
    "                if len(img.shape) == 2:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                out = np.where(labels_unsqueezed, overlay * 255, img ).astype(np.uint8)\n",
    "                img_with_labels = Image.fromarray(out)\n",
    "\n",
    "                ax.imshow(img_with_labels, cmap='binary_r')\n",
    "            else:\n",
    "                ax.imshow(img, cmap='binary_r')\n",
    "\n",
    "        elif k == 1:\n",
    "            gt_seg = optional_crop(load_labels(f\"{PATH}/{dataset}/segmentations/{filename}\") + 1)\n",
    "            ax.imshow(label2rgb(gt_seg, colors=COLORS[1:]))\n",
    "        elif k == 2:\n",
    "            classical_seg = optional_crop(classical_preds[f\"{filename}\"])\n",
    "            ax.imshow(label2rgb(classical_seg + 1, colors=COLORS[1:]))\n",
    "        elif k == 3:\n",
    "            deep_seg = optional_crop(deep_preds[f\"{filename}\"])\n",
    "            ax.imshow(label2rgb(deep_seg + 1, colors=COLORS[1:]))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "outer_grid = gridspec.GridSpec(3, 4, wspace=0.15, hspace=0.2)  # 3 rows (datasets), 4 columns (examples per dataset)\n",
    "train_img_idx = [2, 0, 1]\n",
    "rev = [True, False, True]\n",
    "\n",
    "for i in range(3):  # Dataset rows\n",
    "    chosen_dataset = list(all_classical_preds.keys())[i]\n",
    "    train_filenames = TRAIN_IMG_FNAMES[chosen_dataset]\n",
    "    test_img_fnames = [f for f in sorted(listdir(f\"{PATH}/{chosen_dataset}/images\")) if f not in train_filenames]\n",
    "    if rev[i]:\n",
    "        test_img_fnames = test_img_fnames[::-1]\n",
    "\n",
    "    ax_train_label = plt.Subplot(fig, outer_grid[i, 0])\n",
    "    ax_train_label.set_ylabel(titles[i], fontsize=TITLE_FS, labelpad=PAD-40, rotation=90, va='center')\n",
    "    ax_test_label = plt.Subplot(fig, outer_grid[i, 2])\n",
    "    if i == 0:\n",
    "        ax_train_label.set_title('Train Example', fontsize=TITLE_FS, pad=PAD-10)\n",
    "        ax_test_label.set_title('Test Examples', fontsize=TITLE_FS, pad=PAD-10)\n",
    "\n",
    "    add_stacked_rects(fig, outer_grid[i, 0])\n",
    "    hide_axis_ticks(ax_train_label)\n",
    "    fig.add_subplot(ax_train_label)\n",
    "    hide_axis_ticks(ax_test_label)\n",
    "    fig.add_subplot(ax_test_label)\n",
    "\n",
    "    outer_pos = outer_grid[i, 0].get_position(fig)\n",
    "    # Coordinates of the 2x2 block to be used as background\n",
    "    x0, y0 = outer_pos.x0, outer_pos.y0\n",
    "    width, height = outer_pos.width, outer_pos.height\n",
    "\n",
    "    subfig_titles = [\"Image\", \"Ground truth\", \"Classical\", '+HR ViT']\n",
    "\n",
    "    # chosen_dataset = \"Ni_superalloy_SEM\" #datasets[i]\n",
    "    img_fnames = sorted(listdir(f\"{PATH}/{chosen_dataset}/images\"))\n",
    "    seg_fnames = sorted(listdir(f\"{PATH}/{chosen_dataset}/segmentations\"))\n",
    "\n",
    "    train_example = train_filenames[train_img_idx[i]] + '.tif'\n",
    "\n",
    "    for j in range(4):  # 4 examples per dataset\n",
    "\n",
    "        is_very_top_corner = i == 0 and j == 0\n",
    "        is_train_example = j == 0\n",
    "\n",
    "        example_fname = train_example if j == 0 else test_img_fnames[j]\n",
    "\n",
    "        do_fourplot(chosen_dataset, example_fname, outer_grid[i, j], all_classical_preds[chosen_dataset], all_deep_preds[chosen_dataset], is_train_example, is_very_top_corner)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Make space for suptitle\n",
    "plt.savefig('fig_out/is_benchmark.png' ,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
