{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a5c91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from tifffile import imread\n",
    "\n",
    "from yoeo.main import get_dv2_model, get_upsampler_and_expr, get_hr_feats\n",
    "from yoeo.utils import to_numpy\n",
    "# from interactive_seg_backend import featurise_, FeatureConfig\n",
    "\n",
    "from types import NoneType\n",
    "\n",
    "\n",
    "SEED = 10672\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "056ee84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "COLORS = np.array(color_list) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "039889ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_labels_as_overlay(labels: np.ndarray, img: Image.Image, colors: list, alpha: float=1.0) -> Image.Image:\n",
    "    labels_unsqueezed = np.expand_dims(labels, -1)\n",
    "\n",
    "    overlay = label2rgb(labels, colors=colors[1:], kind='overlay', bg_label=0, image_alpha=1, alpha=alpha)\n",
    "    out = np.where(labels_unsqueezed, overlay * 255, np.array(img)).astype(np.uint8)\n",
    "    img_with_labels = Image.fromarray(out)\n",
    "    return img_with_labels\n",
    "\n",
    "def rescale(arr: np.ndarray, swap_channels: bool=True) -> np.ndarray:\n",
    "    if swap_channels:\n",
    "        arr = np.transpose(arr, (1, 2, 0))\n",
    "    h, w, c = arr.shape\n",
    "    flat = arr.reshape((h * w, c))\n",
    "    rescaled_flat = MinMaxScaler(clip=True).fit_transform(flat)\n",
    "    return rescaled_flat.reshape((h, w, c))\n",
    "\n",
    "def add_inset_zoom(xywh: list[int], fig_xywh: list[float], img_arr: np.ndarray, labels: np.ndarray | None, ax ) -> object:\n",
    "    x0, y0, w, h = xywh\n",
    "    H, W, C = img_arr.shape\n",
    "    inset_data = np.zeros_like(img_arr)\n",
    "    inset_data[y0:y0+h, x0:x0+w, :] = img_arr[y0:y0+h, x0:x0+w, :]\n",
    "\n",
    "    extent = (0, H, W, 0)\n",
    "    axin = ax.inset_axes(\n",
    "        fig_xywh, xlim=(x0, x0+w), ylim=(y0, y0+h))\n",
    "    axin.set_xticks([])\n",
    "    axin.set_yticks([])\n",
    "    #axin.set_axis_off()\n",
    "    if type(labels) != NoneType:\n",
    "        inset_data = label2rgb(labels, img_arr, COLORS[1:], kind='overlay', alpha=0.6, bg_label=-1)\n",
    "        axin.imshow(inset_data,)\n",
    "    else:\n",
    "        axin.imshow(inset_data, cmap=\"binary_r\",) # cmap=\"binary_r\"\n",
    "    ax.indicate_inset_zoom(axin, edgecolor=\"black\", lw=2)\n",
    "    axin.set_ylim((y0 + h, y0))\n",
    "\n",
    "    axin.patch.set_edgecolor('black')  \n",
    "\n",
    "    axin.patch.set_linewidth(4)  \n",
    "\n",
    "    return axin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d7c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"fig_data/is_examples\"\n",
    "\n",
    "img_paths = [\"Battery2.png\", \"biphase_steel_crop.png\", \"cells.jpg\"]\n",
    "imgs = [Image.open(f\"{DATA_PATH}/{path}\").convert('RGB') for path in img_paths]\n",
    "\n",
    "label_paths = [\"2_am_2_labels.tiff\", \"biphase_steel_crop_labels.tiff\", \"cells_lots_labels.tiff\"]\n",
    "labels = [imread(f\"{DATA_PATH}/{path}\") for path in label_paths]\n",
    "\n",
    "imgs_with_labels = [apply_labels_as_overlay(label, img, COLORS) for label, img in zip(labels, imgs)]\n",
    "\n",
    "classical_seg_paths = [\"2_am_2_classical.tiff\", \"biphase_steel_crop_classical.tiff\", \"cells_classical.tiff\"]\n",
    "deep_seg_paths = [\"2_am_2.tiff\", \"biphase_steel_crop.tiff\", \"cells_.tiff\"]\n",
    "\n",
    "classical_segs = [imread(f\"{DATA_PATH}/segs/{path}\") for path in classical_seg_paths]\n",
    "deep_segs = [imread(f\"{DATA_PATH}/segs/{path}\") for path in deep_seg_paths]\n",
    "\n",
    "classical_seg_imgs = [label2rgb(seg, colors=COLORS[1:]) for seg in classical_segs]\n",
    "deep_seg_imgs = [label2rgb(seg, colors=COLORS[1:]) for seg in deep_segs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b472b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
     ]
    }
   ],
   "source": [
    "dv2 = get_dv2_model(True, device=DEVICE)\n",
    "\n",
    "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
    "cfg_path = \"../yoeo/models/configs/combined_no_shift.json\"\n",
    "\n",
    "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a08ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(img: Image.Image) -> np.ndarray:\n",
    "    hr_feats = get_hr_feats(img, dv2, upsampler, DEVICE, n_ch_in=expr.n_ch_in)\n",
    "    hr_feats_np = to_numpy(hr_feats)\n",
    "    hr_feats_np = rescale(hr_feats_np)[:, :, :3].astype(np.float64)\n",
    "    torch.cuda.empty_cache()\n",
    "    return hr_feats_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4fb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [get_feats(img) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85d7a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "TITLE_FS = 25\n",
    "LABEL_FS = 23\n",
    "TICK_FS = 21\n",
    "\n",
    "LABEL_PAD = 0\n",
    "ROT = 90\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(img_paths), ncols=3)\n",
    "fig.set_size_inches((18, 10))\n",
    "\n",
    "titles = [\"Image + labels\", \"Classical Features\", \"Classical + Deep Features\"]\n",
    "materials = [\"Cathode (2 AM)\", \"Biphase Steel\", \"Plant Cells\"]\n",
    "\n",
    "inset_zoom_locs = [(400, 300, 400, 400), (300, 100, 300, 300), (600, 75, 300, 300)]\n",
    "\n",
    "for y, row in enumerate(axs):\n",
    "    if y == 0:\n",
    "        for x, ax in enumerate(row):\n",
    "            ax.set_title(titles[x], fontsize=TITLE_FS)\n",
    "\n",
    "    img_arr = np.array(imgs_with_labels[y])\n",
    "    classical_seg_arr = classical_segs[y]\n",
    "    deep_seg_arr = deep_segs[y]\n",
    "\n",
    "    row[0].imshow(img_arr)\n",
    "    row[1].imshow(classical_seg_imgs[y])\n",
    "    row[2].imshow(deep_seg_imgs[y])\n",
    "\n",
    "    row[0].set_ylabel(materials[y], fontsize=TITLE_FS)\n",
    "\n",
    "    inset_data_arrs = [None, classical_seg_arr, deep_seg_arr]\n",
    "    for x, ax in enumerate(row):\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        add_inset_zoom(inset_zoom_locs[y], [0.65, 0.05, 0.55, 0.55], img_arr, inset_data_arrs[x], ax  )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_out/is_examples.png' ,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
