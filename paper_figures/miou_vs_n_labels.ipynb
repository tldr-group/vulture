{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a61eceb6",
      "metadata": {},
      "source": [
        "- generate all features beforehand and store: may have to cache in .tmp dir\n",
        "- train N classifiers over the N sets of (increasing) labels\n",
        "- apply each N classifier, compute miou, store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c6030966",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N CPUS: 110\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from os import listdir\n",
        "from random import seed\n",
        "\n",
        "from vulture.main import get_dv2_model, get_upsampler_and_expr\n",
        "\n",
        "from interactive_seg_backend.configs import FeatureConfig, TrainingConfig\n",
        "\n",
        "\n",
        "from is_helpers import AllowedDatasets, eval_preds, get_pca_over_images_or_dir, get_and_cache_features_over_images, train_model_over_images, apply_model_over_images\n",
        "    \n",
        "from typing import Literal\n",
        "\n",
        "SEED = 10672\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "seed(SEED)\n",
        "DEVICE = \"cuda:1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73e0b45a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[128, 128, 128, 128]\n"
          ]
        }
      ],
      "source": [
        "dv2 = get_dv2_model(True, device=DEVICE)\n",
        "\n",
        "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
        "cfg_path = \"../vulture/models/configs/combined_no_shift.json\"\n",
        "\n",
        "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "371c7a5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE: bool = False\n",
        "PATH = \"fig_data/is_benchmark\"\n",
        "AllowedDatasets = Literal[\"Ni_superalloy_SEM\", \"T_cell_TEM\", \"Cu_ore_RLM\"]\n",
        "dataset: tuple[AllowedDatasets, ...] = (\"Ni_superalloy_SEM\", \"T_cell_TEM\", \"Cu_ore_RLM\")\n",
        "\n",
        "chosen_dataset = \"Cu_ore_RLM\"\n",
        "fnames = sorted(listdir(f\"{PATH}/{chosen_dataset}/images/\"))\n",
        "images = [f\"{PATH}/{chosen_dataset}/images/{fname}\" for fname in fnames]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2bd6ae",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ca8deb7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = get_pca_over_images_or_dir(images, dv2)\n",
        "\n",
        "feat_cfg = FeatureConfig()\n",
        "train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=True, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\", \"max_depth\": 32,})\n",
        "classical_train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=False, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\", \"max_depth\": 32,})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e123fd3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_and_cache_features_over_images(chosen_dataset, train_cfg, '.tmp', PATH, dv2, upsampler, expr, pca)\n",
        "get_and_cache_features_over_images(chosen_dataset, classical_train_cfg, '.tmp_classical', PATH, dv2, upsampler, expr, pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "42f7bfc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_IMG_FNAMES: dict[AllowedDatasets, list[str]] = {\"Cu_ore_RLM\": [\"004\", \"028\", \"049\", \"077\"], \n",
        "                                                      \"Ni_superalloy_SEM\": [\"000\", \"001\", \"005\", \"007\"], \n",
        "                                                      \"T_cell_TEM\": [\"000\", \"005\", \"007\", \"026\"]\n",
        "                                                      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c4f7ac53",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_labels = TRAIN_IMG_FNAMES[chosen_dataset] #[\"000\", \"001\", \"005\", \"007\"]\n",
        "all_label_paths = sorted(listdir(f\"{PATH}/{chosen_dataset}/labels\"))\n",
        "all_label_fnames = [fname.split('.')[0] for fname in all_label_paths]\n",
        "\n",
        "label_fnames = base_labels + [fname for fname in all_label_fnames if fname not in base_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f618d5bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "( 4/22): 0.8711 +/-0.0332\n",
            "( 5/22): 0.8730 +/-0.0321\n",
            "( 6/22): 0.8727 +/-0.0301\n",
            "( 7/22): 0.8780 +/-0.0299\n",
            "( 8/22): 0.8800 +/-0.0318\n",
            "( 9/22): 0.8821 +/-0.0320\n",
            "(10/22): 0.8835 +/-0.0325\n",
            "(11/22): 0.8859 +/-0.0345\n",
            "(12/22): 0.8883 +/-0.0344\n",
            "(13/22): 0.8923 +/-0.0303\n",
            "(14/22): 0.8956 +/-0.0300\n",
            "(15/22): 0.8963 +/-0.0301\n",
            "(16/22): 0.8966 +/-0.0302\n",
            "(17/22): 0.8976 +/-0.0304\n",
            "(18/22): 0.8998 +/-0.0295\n",
            "(19/22): 0.8993 +/-0.0303\n",
            "(20/22): 0.9000 +/-0.0295\n",
            "(21/22): 0.9020 +/-0.0290\n",
            "(22/22): 0.9027 +/-0.0290\n"
          ]
        }
      ],
      "source": [
        "deep_mious, deep_std_mious = [], []\n",
        "for n_labels in range(4,23):\n",
        "    selected_labels = label_fnames[:n_labels]\n",
        "    feat_paths = [f\"{PATH}/.tmp/{name.split('.')[0]}.npy\" for name in selected_labels]\n",
        "    classifier, _ = train_model_over_images(chosen_dataset, train_cfg, PATH, selected_labels, dv2, upsampler, expr, feat_paths, overwrite_with_gt=True )\n",
        "\n",
        "    all_feat_fnames = [f\"{PATH}/.tmp/{fname}\" for fname in sorted(listdir(f\"{PATH}/.tmp\"))]\n",
        "    deep_preds = apply_model_over_images(chosen_dataset, train_cfg, classifier, PATH, dv2, upsampler, expr, False, -1, pca, all_feat_fnames)\n",
        "    miou, std_miou = eval_preds(chosen_dataset, deep_preds, PATH)\n",
        "    print(f\"({n_labels:2d}/22): {miou:.4f} +/-{std_miou:.4f}\")\n",
        "    deep_mious.append(miou)\n",
        "    deep_std_mious.append(std_miou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0f2b4670",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ni (08/07/25):\n",
        "# ( 4/22): 0.7488 +/-0.1069\n",
        "# ( 5/22): 0.7612 +/-0.0930\n",
        "# ( 6/22): 0.7646 +/-0.0871\n",
        "# ( 7/22): 0.7709 +/-0.0651\n",
        "# ( 8/22): 0.7767 +/-0.0674\n",
        "# ( 9/22): 0.7917 +/-0.0713\n",
        "# (10/22): 0.7935 +/-0.0708\n",
        "# (11/22): 0.7950 +/-0.0749\n",
        "# (12/22): 0.7969 +/-0.0747\n",
        "# (13/22): 0.8000 +/-0.0767\n",
        "# (14/22): 0.8060 +/-0.0783\n",
        "# (15/22): 0.8069 +/-0.0789\n",
        "# (16/22): 0.8117 +/-0.0814\n",
        "# (17/22): 0.8128 +/-0.0868\n",
        "# (18/22): 0.8133 +/-0.0934\n",
        "# (19/22): 0.8168 +/-0.0984\n",
        "# (20/22): 0.8170 +/-0.0967\n",
        "# (21/22): 0.8176 +/-0.0987\n",
        "# (22/22): 0.8196 +/-0.1000\n",
        "\n",
        "# T-Cell\n",
        "# Deep\n",
        "# ( 4/22): 0.6261 +/-0.1678\n",
        "# ( 5/22): 0.6422 +/-0.1681\n",
        "# ( 6/22): 0.6683 +/-0.1707\n",
        "# ( 7/22): 0.6859 +/-0.1694\n",
        "# ( 8/22): 0.6963 +/-0.1687\n",
        "# ( 9/22): 0.7047 +/-0.1690\n",
        "# (10/22): 0.7081 +/-0.1734\n",
        "# (11/22): 0.7103 +/-0.1801\n",
        "# (12/22): 0.7137 +/-0.1871\n",
        "# (13/22): 0.7346 +/-0.1825\n",
        "# (14/22): 0.7413 +/-0.1816\n",
        "# (15/22): 0.7536 +/-0.1789\n",
        "# (16/22): 0.7730 +/-0.1628\n",
        "# (17/22): 0.7779 +/-0.1634\n",
        "# (18/22): 0.7814 +/-0.1636\n",
        "# (19/22): 0.7881 +/-0.1600\n",
        "# (20/22): 0.7959 +/-0.1601\n",
        "# (21/22): 0.8027 +/-0.1578\n",
        "# (22/22): 0.8099 +/-0.1561\n",
        "\n",
        "# Classical\n",
        "# ( 4/22): 0.4520 +/-0.1453\n",
        "# ( 5/22): 0.4597 +/-0.1459\n",
        "# ( 6/22): 0.4836 +/-0.1436\n",
        "# ( 7/22): 0.4941 +/-0.1395\n",
        "# ( 8/22): 0.5031 +/-0.1399\n",
        "# ( 9/22): 0.5051 +/-0.1405\n",
        "# (10/22): 0.5128 +/-0.1441\n",
        "# (11/22): 0.5245 +/-0.1451\n",
        "# (12/22): 0.5264 +/-0.1488\n",
        "# (13/22): 0.5303 +/-0.1491\n",
        "# (14/22): 0.5339 +/-0.1487\n",
        "# (15/22): 0.5440 +/-0.1450\n",
        "# (16/22): 0.5526 +/-0.1461\n",
        "# (17/22): 0.5586 +/-0.1453\n",
        "# (18/22): 0.5613 +/-0.1457\n",
        "# (19/22): 0.5669 +/-0.1426\n",
        "# (20/22): 0.5723 +/-0.1395\n",
        "# (21/22): 0.5744 +/-0.1375\n",
        "# (22/22): 0.5834 +/-0.1343"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "315c3dae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "( 4/22): 0.8531 +/-0.0548\n",
            "( 5/22): 0.8550 +/-0.0478\n",
            "( 6/22): 0.8495 +/-0.0660\n",
            "( 7/22): 0.8511 +/-0.0600\n",
            "( 8/22): 0.8517 +/-0.0663\n",
            "( 9/22): 0.8466 +/-0.0804\n",
            "(10/22): 0.8474 +/-0.0857\n",
            "(11/22): 0.8493 +/-0.0909\n",
            "(12/22): 0.8514 +/-0.0901\n",
            "(13/22): 0.8798 +/-0.0351\n",
            "(14/22): 0.8864 +/-0.0335\n",
            "(15/22): 0.8877 +/-0.0327\n",
            "(16/22): 0.8894 +/-0.0335\n",
            "(17/22): 0.8878 +/-0.0402\n",
            "(18/22): 0.8891 +/-0.0403\n",
            "(19/22): 0.8904 +/-0.0390\n",
            "(20/22): 0.8909 +/-0.0391\n",
            "(21/22): 0.8930 +/-0.0397\n",
            "(22/22): 0.8941 +/-0.0387\n"
          ]
        }
      ],
      "source": [
        "classical_mious, classical_std_mious = [], []\n",
        "for n_labels in range(4,23):\n",
        "    selected_labels = label_fnames[:n_labels]\n",
        "    feat_paths = [f\"{PATH}/.tmp_classical/{name.split('.')[0]}.npy\" for name in selected_labels]\n",
        "    classifier, _ = train_model_over_images(chosen_dataset, classical_train_cfg, PATH, selected_labels, dv2, upsampler, expr, feat_paths, overwrite_with_gt=True )\n",
        "\n",
        "    all_feat_fnames = [f\"{PATH}/.tmp_classical/{fname}\" for fname in sorted(listdir(f\"{PATH}/.tmp_classical\"))]\n",
        "    classical_preds = apply_model_over_images(chosen_dataset, classical_train_cfg, classifier, PATH, dv2, upsampler, expr, False, -1, pca, all_feat_fnames)\n",
        "    miou, std_miou = eval_preds(chosen_dataset, classical_preds, PATH)\n",
        "    print(f\"({n_labels:2d}/22): {miou:.4f} +/-{std_miou:.4f}\")\n",
        "    classical_mious.append(miou)\n",
        "    classical_std_mious.append(std_miou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cc846f4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dict = {}\n",
        "data_dict[\"classical_miou\"] = classical_mious\n",
        "data_dict[\"classical_miou_std\"] = classical_std_mious\n",
        "data_dict[\"classical_preds\"] = classical_preds\n",
        "\n",
        "data_dict[\"deep_miou\"] = deep_mious\n",
        "data_dict[\"deep_miou_std\"] = deep_std_mious\n",
        "data_dict[\"deep_preds\"] = deep_preds\n",
        "\n",
        "if SAVE:\n",
        "    np.save(f\"{PATH}/miou_results/{chosen_dataset}.npy\", data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "be1baf02",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"font.family\"] = \"serif\"\n",
        "\n",
        "\n",
        "TITLE_FS = 25\n",
        "LABEL_FS = 23\n",
        "TICK_FS = 21\n",
        "\n",
        "\n",
        "n_labels = [4 + i for i in range(0, len(deep_mious))]\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = plt.gca()\n",
        "\n",
        "plt.plot(n_labels, classical_mious, marker='.', lw=3, ms=15, label='Classical')\n",
        "plt.plot(n_labels, deep_mious, marker='.', lw=3, ms=15, label='+HR ViT')\n",
        "\n",
        "plt.xlabel('# labelled images', fontsize=LABEL_FS)\n",
        "plt.ylabel('mIoU', fontsize=LABEL_FS)\n",
        "ax.tick_params(axis='both', labelsize=TICK_FS)\n",
        "\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.legend(fontsize=TICK_FS)\n",
        "plt.tight_layout(pad=2.5)\n",
        "plt.savefig(f'fig_out/{chosen_dataset}_miou_vs_n_labels.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a2821dbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from interactive_seg_backend.file_handling import load_image, load_labels\n",
        "from skimage.color import label2rgb\n",
        "\n",
        "\n",
        "# cmap = [\n",
        "#             \"#fafafa\",\n",
        "#             \"#1f77b4\",\n",
        "#             \"#ff7f0e\",\n",
        "#             \"#2ca02c\",\n",
        "#             \"#d62728\",\n",
        "#         ]\n",
        "# color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
        "color_list = [[255, 255, 255], [0, 62, 131], [181, 209, 204], [250, 43, 0], [255, 184, 82]]\n",
        "COLORS = np.array(color_list) / 255.0\n",
        "\n",
        "def apply_labels_as_overlay(labels: np.ndarray, img: Image.Image, colors: list, alpha: float=1.0) -> Image.Image:\n",
        "    labels_unsqueezed = np.expand_dims(labels, -1)\n",
        "\n",
        "    overlay = label2rgb(labels, colors=colors[1:], kind='overlay', bg_label=0, image_alpha=1, alpha=alpha)\n",
        "    out = np.where(labels_unsqueezed, overlay * 255, np.array(img)).astype(np.uint8)\n",
        "    img_with_labels = Image.fromarray(out)\n",
        "    return img_with_labels\n",
        "\n",
        "def add_inset_zoom(xywh: list[int], fig_xywh: list[float], img_arr: np.ndarray, labels: np.ndarray | None, ax ) -> object:\n",
        "    x0, y0, w, h = xywh\n",
        "    H, W, C = img_arr.shape\n",
        "    inset_data = np.zeros_like(img_arr)\n",
        "    inset_data[y0:y0+h, x0:x0+w, :] = img_arr[y0:y0+h, x0:x0+w, :]\n",
        "\n",
        "    axin = ax.inset_axes(\n",
        "        fig_xywh, xlim=(x0, x0+w), ylim=(y0, y0+h))\n",
        "    axin.set_xticks([])\n",
        "    axin.set_yticks([])\n",
        "    #axin.set_axis_off()\n",
        "    if labels is not None:\n",
        "        inset_data = label2rgb(labels, img_arr, COLORS[1:], kind='overlay', alpha=0.6, bg_label=-1)\n",
        "        axin.imshow(inset_data,)\n",
        "    else:\n",
        "        axin.imshow(inset_data, cmap=\"binary_r\",) # cmap=\"binary_r\"\n",
        "    ax.indicate_inset_zoom(axin, edgecolor=\"black\", lw=2)\n",
        "    axin.set_ylim((y0 + h, y0))\n",
        "\n",
        "    axin.patch.set_edgecolor('black')  \n",
        "\n",
        "    axin.patch.set_linewidth(4)  \n",
        "\n",
        "    return axin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f481051a",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "n_examples = 5\n",
        "width = 2.75\n",
        "n_cols = 4\n",
        "fig, axs = plt.subplots(nrows=n_examples, ncols=n_cols, figsize=(width * n_cols, width * n_examples))\n",
        "\n",
        "step = len(all_label_fnames) // n_examples\n",
        "fnames = all_label_fnames[::step][:n_examples]\n",
        "\n",
        "\n",
        "images = {fname: Image.fromarray(load_image(f\"{PATH}/{chosen_dataset}/images/{fname}.tif\")).convert('RGB') for fname in all_label_fnames}\n",
        "labels = {fname: (load_labels(f\"{PATH}/{chosen_dataset}/labels/{fname}.tif\")) for fname in all_label_fnames}\n",
        "segs = {fname: (load_labels(f\"{PATH}/{chosen_dataset}/segmentations/{fname}.tif\")) for fname in all_label_fnames}\n",
        "\n",
        "\n",
        "titles = [\"Image + labels\", \" Ground truth\", \"Classical\", \"+HR ViT\"]\n",
        "for j in range(n_cols):\n",
        "    axs[0, j].set_title(titles[j], fontsize=TITLE_FS)\n",
        "\n",
        "\n",
        "for i, fname in enumerate(fnames):\n",
        "    img, label, seg = images[fname], labels[fname], segs[fname]\n",
        "    if label.shape[0] == 1:\n",
        "        label = label[0]\n",
        "    overlay_img = apply_labels_as_overlay(label, img, COLORS)\n",
        "\n",
        "    ground_truth = label2rgb(seg + 1, colors=COLORS[1:])\n",
        "    classical_pred = label2rgb(classical_preds[f\"{fname}.tif\"] + 1, colors=COLORS[1:])\n",
        "    deep_pred = label2rgb(deep_preds[f\"{fname}.tif\"] + 1, colors=COLORS[1:])\n",
        "\n",
        "\n",
        "\n",
        "    axs[i, 0].imshow(overlay_img, cmap='binary_r')\n",
        "    axs[i, 1].imshow(ground_truth)\n",
        "    add_inset_zoom([45, 110, 100, 100], [0.7, 0.15, 0.3, 0.3], ground_truth, None, axs[i, 1])\n",
        "    axs[i, 2].imshow(classical_pred)\n",
        "    add_inset_zoom([45, 110, 100, 100], [0.7, 0.15, 0.3, 0.3], classical_pred, None, axs[i, 2])\n",
        "    axs[i, 3].imshow(deep_pred)\n",
        "    add_inset_zoom([45, 110, 100, 100], [0.7, 0.15, 0.3, 0.3], deep_pred, None, axs[i, 3])\n",
        "\n",
        "    for ax in axs[i]:\n",
        "        ax.set_axis_off()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'fig_out/{chosen_dataset}_max_labels_preds.png', bbox_inches='tight')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
