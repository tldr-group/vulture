{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61eceb6",
   "metadata": {},
   "source": [
    "- generate all features beforehand and store: may have to cache in .tmp dir\n",
    "- train N classifiers over the N sets of (increasing) labels\n",
    "- apply each N classifier, compute miou, store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6030966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N CPUS: 110\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from os import listdir\n",
    "\n",
    "from yoeo.main import get_dv2_model, get_upsampler_and_expr\n",
    "\n",
    "from interactive_seg_backend.configs import FeatureConfig, TrainingConfig\n",
    "\n",
    "\n",
    "from is_helpers import AllowedDatasets, eval_preds, get_pca_over_images_or_dir, get_and_cache_features_over_images, train_model_over_images, apply_model_over_images\n",
    "    \n",
    "from typing import Literal\n",
    "\n",
    "SEED = 10672\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e0b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
     ]
    }
   ],
   "source": [
    "dv2 = get_dv2_model(True, device=DEVICE)\n",
    "\n",
    "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
    "cfg_path = \"../yoeo/models/configs/combined_no_shift.json\"\n",
    "\n",
    "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371c7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"fig_data/is_benchmark\"\n",
    "AllowedDatasets = Literal[\"Ni_superalloy_SEM\", \"T_cell_TEM\", \"Cu_ore_RLM\"]\n",
    "dataset: tuple[AllowedDatasets, ...] = (\"Ni_superalloy_SEM\", \"T_cell_TEM\", \"Cu_ore_RLM\")\n",
    "\n",
    "chosen_dataset = \"Cu_ore_RLM\"\n",
    "fnames = sorted(listdir(f\"{PATH}/{chosen_dataset}/images/\"))\n",
    "images = [f\"{PATH}/{chosen_dataset}/images/{fname}\" for fname in fnames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bd6ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8deb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = get_pca_over_images_or_dir(images, dv2)\n",
    "\n",
    "feat_cfg = FeatureConfig()\n",
    "train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=True, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\", \"max_depth\": 32,})\n",
    "classical_train_cfg = TrainingConfig(feat_cfg, n_samples=-1, add_dino_features=False, classifier='xgb', classifier_params = {\"class_weight\": \"balanced\", \"max_depth\": 32,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e123fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_cache_features_over_images(chosen_dataset, train_cfg, '.tmp', PATH, dv2, upsampler, expr, pca)\n",
    "get_and_cache_features_over_images(chosen_dataset, classical_train_cfg, '.tmp_classical', PATH, dv2, upsampler, expr, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f7bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_FNAMES: dict[AllowedDatasets, list[str]] = {\"Cu_ore_RLM\": [\"004\", \"028\", \"049\", \"077\"], \n",
    "                                                      \"Ni_superalloy_SEM\": [\"000\", \"001\", \"005\", \"007\"], \n",
    "                                                      \"T_cell_TEM\": [\"000\", \"005\", \"007\", \"026\"]\n",
    "                                                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f7ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_labels = TRAIN_IMG_FNAMES[chosen_dataset] #[\"000\", \"001\", \"005\", \"007\"]\n",
    "all_label_paths = sorted(listdir(f\"{PATH}/{chosen_dataset}/labels\"))\n",
    "all_label_fnames = [fname.split('.')[0] for fname in all_label_paths]\n",
    "\n",
    "label_fnames = base_labels + [fname for fname in all_label_fnames if fname not in base_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f618d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 4/22): 0.8572 +/-0.0338\n",
      "( 5/22): 0.8541 +/-0.0333\n",
      "( 6/22): 0.8592 +/-0.0296\n",
      "( 7/22): 0.8613 +/-0.0289\n",
      "( 8/22): 0.8638 +/-0.0303\n",
      "( 9/22): 0.8673 +/-0.0276\n",
      "(10/22): 0.8668 +/-0.0292\n",
      "(11/22): 0.8709 +/-0.0266\n",
      "(12/22): 0.8721 +/-0.0263\n",
      "(13/22): 0.8748 +/-0.0254\n",
      "(14/22): 0.8774 +/-0.0244\n",
      "(15/22): 0.8781 +/-0.0242\n",
      "(16/22): 0.8782 +/-0.0240\n",
      "(17/22): 0.8786 +/-0.0232\n",
      "(18/22): 0.8815 +/-0.0224\n",
      "(19/22): 0.8815 +/-0.0224\n",
      "(20/22): 0.8818 +/-0.0220\n",
      "(21/22): 0.8813 +/-0.0238\n",
      "(22/22): 0.8820 +/-0.0235\n"
     ]
    }
   ],
   "source": [
    "deep_mious, deep_std_mious = [], []\n",
    "for n_labels in range(4,23):\n",
    "    selected_labels = label_fnames[:n_labels]\n",
    "    feat_paths = [f\"{PATH}/.tmp/{name.split('.')[0]}.npy\" for name in selected_labels]\n",
    "    classifier, _ = train_model_over_images(chosen_dataset, train_cfg, PATH, selected_labels, dv2, upsampler, expr, feat_paths )\n",
    "\n",
    "    all_feat_fnames = [f\"{PATH}/.tmp/{fname}\" for fname in sorted(listdir(f\"{PATH}/.tmp\"))]\n",
    "    deep_preds = apply_model_over_images(chosen_dataset, train_cfg, classifier, PATH, dv2, upsampler, expr, False, -1, pca, all_feat_fnames)\n",
    "    miou, std_miou = eval_preds(chosen_dataset, deep_preds, PATH)\n",
    "    print(f\"({n_labels:2d}/22): {miou:.4f} +/-{std_miou:.4f}\")\n",
    "    deep_mious.append(miou)\n",
    "    deep_std_mious.append(std_miou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315c3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 4/22): 0.8390 +/-0.0538\n",
      "( 5/22): 0.8384 +/-0.0576\n",
      "( 6/22): 0.8322 +/-0.0679\n",
      "( 7/22): 0.8311 +/-0.0688\n",
      "( 8/22): 0.8317 +/-0.0731\n",
      "( 9/22): 0.8344 +/-0.0706\n",
      "(10/22): 0.8345 +/-0.0768\n",
      "(11/22): 0.8351 +/-0.0822\n",
      "(12/22): 0.8347 +/-0.0838\n",
      "(13/22): 0.8630 +/-0.0307\n",
      "(14/22): 0.8689 +/-0.0289\n",
      "(15/22): 0.8701 +/-0.0287\n",
      "(16/22): 0.8716 +/-0.0302\n",
      "(17/22): 0.8701 +/-0.0359\n",
      "(18/22): 0.8698 +/-0.0379\n",
      "(19/22): 0.8716 +/-0.0353\n",
      "(20/22): 0.8716 +/-0.0353\n",
      "(21/22): 0.8740 +/-0.0349\n",
      "(22/22): 0.8743 +/-0.0343\n"
     ]
    }
   ],
   "source": [
    "classical_mious, classical_std_mious = [], []\n",
    "for n_labels in range(4,23):\n",
    "    selected_labels = label_fnames[:n_labels]\n",
    "    feat_paths = [f\"{PATH}/.tmp_classical/{name.split('.')[0]}.npy\" for name in selected_labels]\n",
    "    classifier, _ = train_model_over_images(chosen_dataset, classical_train_cfg, PATH, selected_labels, dv2, upsampler, expr, feat_paths )\n",
    "\n",
    "    all_feat_fnames = [f\"{PATH}/.tmp_classical/{fname}\" for fname in sorted(listdir(f\"{PATH}/.tmp_classical\"))]\n",
    "    classical_preds = apply_model_over_images(chosen_dataset, classical_train_cfg, classifier, PATH, dv2, upsampler, expr, False, -1, pca, all_feat_fnames)\n",
    "    miou, std_miou = eval_preds(chosen_dataset, classical_preds, PATH)\n",
    "    print(f\"({n_labels:2d}/22): {miou:.4f} +/-{std_miou:.4f}\")\n",
    "    classical_mious.append(miou)\n",
    "    classical_std_mious.append(std_miou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc846f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "data_dict[\"classical_miou\"] = classical_mious\n",
    "data_dict[\"classical_miou_std\"] = classical_std_mious\n",
    "data_dict[\"classical_preds\"] = classical_preds\n",
    "\n",
    "data_dict[\"deep_miou\"] = deep_mious\n",
    "data_dict[\"deep_miou_std\"] = deep_std_mious\n",
    "data_dict[\"deep_preds\"] = deep_preds\n",
    "\n",
    "np.save(f\"{PATH}/miou_results/{chosen_dataset}.npy\", data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1baf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "\n",
    "TITLE_FS = 25\n",
    "LABEL_FS = 23\n",
    "TICK_FS = 21\n",
    "\n",
    "\n",
    "n_labels = [4 + i for i in range(0, len(deep_mious))]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.plot(n_labels, classical_mious, marker='.', lw=3, ms=15, label='Classical')\n",
    "plt.plot(n_labels, deep_mious, marker='.', lw=3, ms=15, label='+HR ViT')\n",
    "\n",
    "plt.xlabel('# labelled images', fontsize=LABEL_FS)\n",
    "plt.ylabel('mIoU', fontsize=LABEL_FS)\n",
    "ax.tick_params(axis='both', labelsize=TICK_FS)\n",
    "\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend(fontsize=TICK_FS)\n",
    "plt.tight_layout(pad=2.5)\n",
    "plt.savefig(f'fig_out/{chosen_dataset}_miou_vs_n_labels.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2821dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from interactive_seg_backend.file_handling import load_image, load_labels\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "\n",
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "COLORS = np.array(color_list) / 255.0\n",
    "\n",
    "def apply_labels_as_overlay(labels: np.ndarray, img: Image.Image, colors: list, alpha: float=1.0) -> Image.Image:\n",
    "    labels_unsqueezed = np.expand_dims(labels, -1)\n",
    "\n",
    "    overlay = label2rgb(labels, colors=colors[1:], kind='overlay', bg_label=0, image_alpha=1, alpha=alpha)\n",
    "    out = np.where(labels_unsqueezed, overlay * 255, np.array(img)).astype(np.uint8)\n",
    "    img_with_labels = Image.fromarray(out)\n",
    "    return img_with_labels\n",
    "\n",
    "def add_inset_zoom(xywh: list[int], fig_xywh: list[float], img_arr: np.ndarray, labels: np.ndarray | None, ax ) -> object:\n",
    "    x0, y0, w, h = xywh\n",
    "    H, W, C = img_arr.shape\n",
    "    inset_data = np.zeros_like(img_arr)\n",
    "    inset_data[y0:y0+h, x0:x0+w, :] = img_arr[y0:y0+h, x0:x0+w, :]\n",
    "\n",
    "    axin = ax.inset_axes(\n",
    "        fig_xywh, xlim=(x0, x0+w), ylim=(y0, y0+h))\n",
    "    axin.set_xticks([])\n",
    "    axin.set_yticks([])\n",
    "    #axin.set_axis_off()\n",
    "    if labels is not None:\n",
    "        inset_data = label2rgb(labels, img_arr, COLORS[1:], kind='overlay', alpha=0.6, bg_label=-1)\n",
    "        axin.imshow(inset_data,)\n",
    "    else:\n",
    "        axin.imshow(inset_data, cmap=\"binary_r\",) # cmap=\"binary_r\"\n",
    "    ax.indicate_inset_zoom(axin, edgecolor=\"black\", lw=2)\n",
    "    axin.set_ylim((y0 + h, y0))\n",
    "\n",
    "    axin.patch.set_edgecolor('black')  \n",
    "\n",
    "    axin.patch.set_linewidth(4)  \n",
    "\n",
    "    return axin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "n_examples = 5\n",
    "width = 2.75\n",
    "n_cols = 4\n",
    "fig, axs = plt.subplots(nrows=n_examples, ncols=n_cols, figsize=(width * n_cols, width * n_examples))\n",
    "\n",
    "step = len(all_label_fnames) // n_examples\n",
    "fnames = all_label_fnames[::step][:n_examples]\n",
    "\n",
    "\n",
    "images = {fname: Image.fromarray(load_image(f\"{PATH}/{chosen_dataset}/images/{fname}.tif\")).convert('RGB') for fname in all_label_fnames}\n",
    "labels = {fname: (load_labels(f\"{PATH}/{chosen_dataset}/labels/{fname}.tif\")) for fname in all_label_fnames}\n",
    "segs = {fname: (load_labels(f\"{PATH}/{chosen_dataset}/segmentations/{fname}.tif\")) for fname in all_label_fnames}\n",
    "\n",
    "\n",
    "titles = [\"Image + labels\", \" Ground truth\", \"Classical\", \"+HR ViT\"]\n",
    "for j in range(n_cols):\n",
    "    axs[0, j].set_title(titles[j], fontsize=TITLE_FS)\n",
    "\n",
    "\n",
    "for i, fname in enumerate(fnames):\n",
    "    img, label, seg = images[fname], labels[fname], segs[fname]\n",
    "    if label.shape[0] == 1:\n",
    "        label = label[0]\n",
    "    overlay_img = apply_labels_as_overlay(label, img, COLORS)\n",
    "\n",
    "    ground_truth = label2rgb(seg + 1, colors=COLORS[1:])\n",
    "    classical_pred = label2rgb(classical_preds[f\"{fname}.tif\"] + 1, colors=COLORS[1:])\n",
    "    deep_pred = label2rgb(deep_preds[f\"{fname}.tif\"] + 1, colors=COLORS[1:])\n",
    "\n",
    "\n",
    "\n",
    "    axs[i, 0].imshow(overlay_img, cmap='binary_r')\n",
    "    axs[i, 1].imshow(ground_truth)\n",
    "    add_inset_zoom([45, 110, 100, 100], [0.7, 0.15, 0.3, 0.3], ground_truth, None, axs[i, 1])\n",
    "    axs[i, 2].imshow(classical_pred)\n",
    "    add_inset_zoom([45, 110, 100, 100], [0.7, 0.15, 0.3, 0.3], classical_pred, None, axs[i, 2])\n",
    "    axs[i, 3].imshow(deep_pred)\n",
    "    add_inset_zoom([45, 110, 100, 100], [0.7, 0.15, 0.3, 0.3], deep_pred, None, axs[i, 3])\n",
    "\n",
    "    for ax in axs[i]:\n",
    "        ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'fig_out/{chosen_dataset}_max_labels_preds.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff294f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
