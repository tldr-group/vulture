{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5df35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N CPUS: 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1e11e21050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from tifffile import imread\n",
    "\n",
    "from yoeo.main import get_dv2_model, get_upsampler_and_expr, get_hr_feats, get_lr_feats\n",
    "from yoeo.utils import convert_image, to_numpy, closest_crop, do_2D_pca\n",
    "from interactive_seg_backend import featurise_, FeatureConfig\n",
    "\n",
    "\n",
    "SEED = 10672\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d578d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb534fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(arr: np.ndarray, swap_channels: bool=True) -> np.ndarray:\n",
    "    if swap_channels:\n",
    "        arr = np.transpose(arr, (1, 2, 0))\n",
    "    h, w, c = arr.shape\n",
    "    flat = arr.reshape((h * w, c))\n",
    "    rescaled_flat = MinMaxScaler(clip=True).fit_transform(flat)\n",
    "    return rescaled_flat.reshape((h, w, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea025d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "# color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "color_list = [[255, 255, 255], [0, 62, 131], [181, 209, 204], [250, 43, 0], [255, 184, 82]]\n",
    "COLORS = np.array(color_list) / 255.0\n",
    "\n",
    "img = Image.open('fig_data/intro_column/needle_block.jpg')\n",
    "labels = imread('fig_data/intro_column/glutamic_more.tiff')\n",
    "\n",
    "labels_unsqueezed = np.expand_dims(labels, -1)\n",
    "\n",
    "overlay = label2rgb(labels, colors=COLORS[1:], kind='overlay', bg_label=0, image_alpha=1, alpha=1)\n",
    "out = np.where(labels_unsqueezed, overlay * 255, np.array(img)).astype(np.uint8)\n",
    "img_with_labels = Image.fromarray(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb2252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_cfg = FeatureConfig()\n",
    "classical_feats = featurise_(np.array(img), classical_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482a94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_reduced = do_2D_pca(classical_feats.transpose(-1, 0, 1), 3, post_norm='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e092d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/ywyue_FiT3D_main\n"
     ]
    }
   ],
   "source": [
    "dv2 = get_dv2_model(True, device=DEVICE)\n",
    "\n",
    "model_path = \"../trained_models/e5000_full_fit_reg.pth\"\n",
    "cfg_path = \"../yoeo/models/configs/combined_no_shift.json\"\n",
    "\n",
    "upsampler, expr = get_upsampler_and_expr(model_path, cfg_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc48622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = closest_crop(img.height, img.width)\n",
    "lr_feats, _ = get_lr_feats(dv2, [convert_image(img, tr)], fit3d=True)\n",
    "lr_feats = F.interpolate(lr_feats, (img.height, img.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f95c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_feats_np = to_numpy(lr_feats)\n",
    "lr_feats_np = rescale(lr_feats_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0506f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(629, 750, 128)\n"
     ]
    }
   ],
   "source": [
    "hr_feats = get_hr_feats(img, dv2, upsampler, DEVICE, n_ch_in=expr.n_ch_in)\n",
    "hr_feats_np = to_numpy(hr_feats)\n",
    "hr_feats_np = rescale(hr_feats_np)\n",
    "print(hr_feats_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caaa6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_seg = imread('fig_data/intro_column/glutamic_no_crf_classical.tiff')\n",
    "classical_seg_img = label2rgb(classical_seg, colors=COLORS[1:])\n",
    "deep_seg = imread('fig_data/intro_column/glutamic_no_crf_deep.tiff')\n",
    "deep_seg_img = label2rgb(deep_seg, colors=COLORS[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca7d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "LABEL_FS = 23\n",
    "LABEL_PAD = 0\n",
    "ROT = 90\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2)\n",
    "fig.set_size_inches((8.6, 11))\n",
    "\n",
    "\n",
    "titles = ('Image + labels', 'ViT features (LR)', 'Classical Features', 'ViT features (HR)', 'Classical Seg.', '+ HR ViT features')\n",
    "for i, a in enumerate(axs.flatten()):\n",
    "    a.set_xticklabels([])\n",
    "    a.set_yticklabels([])\n",
    "    # a.tick_params(which=\"both\", bottom=False, top=False, left=False, right=False)\n",
    "    # a.set_aspect('equal')\n",
    "    a.set_axis_off()\n",
    "\n",
    "    a.set_title(titles[i], fontsize=LABEL_FS)\n",
    "\n",
    "    # if i == 0:\n",
    "    #     a.set_ylabel('Image', fontsize=20)\n",
    "    # elif i == 1:\n",
    "    #     # a.yaxis.set_label_position(\"right\")\n",
    "    #     a.set_ylabel('ViT features (LR)', fontsize=LABEL_FS, rotation=ROT, labelpad=LABEL_PAD)\n",
    "    # elif i == 2:\n",
    "    #     a.set_ylabel('Classical Features', fontsize=LABEL_FS)\n",
    "    # elif i == 3:\n",
    "    #     # a.yaxis.set_label_position(\"right\")\n",
    "    #     a.set_ylabel('ViT features (HR)', fontsize=LABEL_FS, rotation=ROT, labelpad=LABEL_PAD)\n",
    "    # elif i == 4:\n",
    "    #     a.set_ylabel('Classical Seg.', fontsize=LABEL_FS)\n",
    "    # elif i == 5:\n",
    "    #     # a.yaxis.set_label_position(\"right\")\n",
    "    #     a.set_ylabel('+ HR ViT features', fontsize=LABEL_FS, rotation=ROT, labelpad=LABEL_PAD)\n",
    "    \n",
    "\n",
    "axs[0, 0].imshow(img_with_labels)\n",
    "axs[0, 1].imshow(lr_feats_np[:, :, :3].astype(np.float64))\n",
    "axs[1, 0].imshow(classical_reduced)\n",
    "axs[1, 1].imshow(hr_feats_np[:, :, :3].astype(np.float64))\n",
    "axs[2, 0].imshow(classical_seg_img)\n",
    "axs[2, 1].imshow(deep_seg_img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=-0.16)\n",
    "plt.margins(x=0)\n",
    "plt.savefig('fig_out/intro_column.png' ,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4caa5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
